{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# デュアルネットワーク学習用のnotebook\n",
    "https://stats.stackexchange.com/questions/248511/purpose-of-l2-normalization-for-triplet-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "場合によってはGPUの指定が必要かもしれない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras関連"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pip/koki_ishizuka/.conda/envs/py35-zukapy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Layer,Lambda\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータ設定\n",
    "- 保存先のディレクトリやファイル名に影響するため慎重に。\n",
    "- Improved Triplet Lossにおいては、`alpha > beta`を満たす必要がある(元論文)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力画像の情報"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imheight = 128\n",
    "imwidth = 128\n",
    "channels = 3\n",
    "category = 'T_Shirt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 出力次元\n",
    "- Dualなネットワークではconcatするため出力次元はdense_num*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_dense_num = 350\n",
    "shallow_dense_num = 150\n",
    "vec_length= 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet Loss設定\n",
    "- `ALPHA=D(a,p)とD(a,n)の相対距離を抑制`, `BETA=D(a,p)の絶対距離を制御`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA=0.1\n",
    "BETA=0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pip/koki_ishizuka/.conda/envs/py35-zukapy/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "#include_top=false => Dense不要\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_tensor=Input(shape=(imwidth, imheight, channels)), input_shape=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習しないように重みを固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:15]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワーク構造を定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 浅いネットワーク(shallow_model)を作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元々(32,(4,4))だったが，奇数フィルタの方がいいらしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(imwidth, imheight, channels))\n",
    "conv1 = Conv2D(32, (4,4) , padding='same', activation='relu')(inputs)\n",
    "pool1 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(conv1)\n",
    "conv2 = Conv2D(32, (4,4) , padding='same', activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(conv2)\n",
    "flatten = Flatten()(pool2) \n",
    "dense_layer = Dense(shallow_dense_num, activation='relu')(flatten)\n",
    "norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer_shallow')(dense_layer)\n",
    "shallow_model=Model(inputs=inputs,outputs=norm_layer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shallow_modelと、VGGを通したdeepなモデルと結合しモデル全体を作成する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embNet():\n",
    "    shallow_inputs = Input(shape=(imwidth, imheight, channels))\n",
    "    x = base_model.output\n",
    "    conv1 = Conv2D(filters=32, kernel_size=(3,3) , padding='same', activation='relu')(x)\n",
    "    conv2 = Conv2D(filters=32, kernel_size=(3,3) , padding='same', activation='relu')(conv1)\n",
    "    flatten = Flatten()(conv2) \n",
    "    dense_layer = Dense(deep_dense_num, activation='relu')(flatten)\n",
    "    norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer_deep')(dense_layer)\n",
    "    # inputに対してshallow_modelのoutputも用意\n",
    "    x1 = norm_layer\n",
    "    x2 = shallow_model(shallow_inputs)\n",
    "    concat_out = concatenate([norm_layer,x2])\n",
    "    dense_linear = Dense(units=vec_length, activation='linear')(concat_out)\n",
    "#     l2norm_out = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer_whole')(concat_out)\n",
    "#     main_out =  Dense(units=vec_length, activation='relu')(l2norm_out)\n",
    "    return Model(inputs=[base_model.input,shallow_inputs],outputs=dense_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inputを定義する\n",
    "- create embNet()の中でInputを定義すると明示的に3つの入力が分けられない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define three Inputs\n",
    "a_in = Input(shape = (imheight, imwidth, channels), name='anchor_input')\n",
    "p_in = Input(shape = (imheight, imwidth, channels), name='positive_input')\n",
    "n_in = Input(shape = (imheight, imwidth, channels), name='negative_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### これは不明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_in = Input(shape = (imheight, imwidth, channels), name='sanchor_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **後に埋め込み用のモデルとして利用するため**ベクトル化までの部分を別で定義しておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_embNet = create_embNet()\n",
    "shop_embNet = create_embNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 埋め込み用のベクトルもあらかじめ用意する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con_embNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_emb = shop_embNet([a_in,a_in])\n",
    "p_emb = con_embNet([p_in,p_in])\n",
    "n_emb = con_embNet([n_in,n_in])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet Loss\n",
    "- 通常のTriplet Lossを用いる場合はこちらを使う。\n",
    "- `Loss=max[D(a,p)-D(a-n)+margin,0] where D(A,B)=||A-B||_2^2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def triplet_loss(self, inputs):\n",
    "        a, p, n = inputs\n",
    "        p_dist = K.sum(K.square(a-p), axis=-1)\n",
    "        n_dist = K.sum(K.square(a-n), axis=-1)\n",
    "        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'alpha': self.alpha}\n",
    "        base_config = super(TripletLossLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lossレイヤの定義とモデルのコンパイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer that computes the triplet loss from anchor, positive and negative embedding vectors\n",
    "triplet_loss_layer = TripletLossLayer(alpha=ALPHA, name='triplet_loss_layer')([a_emb, p_emb, n_emb])\n",
    "\n",
    "# Model that can be trained with anchor, positive negative images\n",
    "tripletNet = Model([a_in, p_in, n_in], triplet_loss_layer)\n",
    "tripletNet.compile(loss=None, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(con_embNet).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Triplet Lossの場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Triplet Loss\n",
    "- `Loss=[D(a,p)-D(a,n)+ALPHA]+[D(a,p)-BETA]`\n",
    "- Positiveを短くする方向に制御する\n",
    "\n",
    "https://qiita.com/tancoro/items/35d0925de74f21bfff14#improved-triplet-loss\n",
    "\n",
    "<img src=\"./readme_imgs/improved.PNG\" width=30% align=left><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Improved Triplet Loss用にレイヤを改変"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, beta, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def triplet_loss(self, inputs):\n",
    "        a, p, n = inputs\n",
    "        p_dist = K.sum(K.square(a-p), axis=-1)\n",
    "        n_dist = K.sum(K.square(a-n), axis=-1)\n",
    "        pn_dist = K.sum(K.square(p-n), axis=-1)\n",
    "        return K.sum(K.maximum((p_dist - n_dist + self.alpha), 0) + K.maximum((p_dist - self.beta), 0), axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'alpha': self.alpha}\n",
    "        base_config = super(TripletLossLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの定義とコンパイル\n",
    "- ハイパーパラメータとしてBETAが増えていることに注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer that computes the triplet loss from anchor, positive and negative embedding vectors\n",
    "triplet_loss_layer = TripletLossLayer(alpha=ALPHA, beta=BETA, name='triplet_loss_layer')([a_emb, p_emb, n_emb])\n",
    "\n",
    "# Model that can be trained with anchor, positive negative images\n",
    "tripletNet = Model([a_in, p_in, n_in], triplet_loss_layer)\n",
    "tripletNet.compile(loss=None, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの用意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `T_Shirt_all/`(クロップ済み画像が商品id別に保存されたディレクトリ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = './dataset/T_Shirt_all/'\n",
    "category = 'T_Shirt'\n",
    "ids = sorted([x for x in os.listdir(BASE_PATH)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TripletのPATHを返す関数\n",
    "- 入力:`ids=商品id群`, `BASE_PATH=商品群ディレクトリへのPATH`\n",
    "- `[consumer_ancのパス, shop_posのパス, shop_negのパス]`のような組を返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "def get_triplets(ids,BASE_PATH):\n",
    "    triplets=[]\n",
    "    for id_ in tqdm(ids):\n",
    "        files = sorted([BASE_PATH+id_+'/'+x for x in os.listdir(BASE_PATH+id_)])\n",
    "        con = sorted([x for x in files if 'comsumer' in x])\n",
    "        shop = sorted([x for x in files if 'shop' in x ])\n",
    "        combs = list(itertools.product(tuple(con),tuple(shop)))\n",
    "        for comb in combs:\n",
    "            comb = list(comb)\n",
    "            neg_id = random.choice([x for x in ids if x != id_])\n",
    "            neg_file = random.choice([BASE_PATH+neg_id+'/'+x for x in os.listdir(BASE_PATH+neg_id) if 'shop' in x])\n",
    "            comb.append(neg_file)\n",
    "            triplets.append(comb)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 商品idの単位でTrain/Testを分割する\n",
    "- Seed値(random_state)は固定\n",
    "- random.choice()はブートストラップサンプリングのため、`train_test_split()`を利用\n",
    "- idsオブジェクトは以降使わないためここで削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pip/koki_ishizuka/.conda/envs/py35-zukapy/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_ids,test_ids=train_test_split(ids,test_size=0.33,random_state=0)\n",
    "del ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4123"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26291"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 0\n",
    "for id_ in train_ids:\n",
    "    length += len(os.listdir(BASE_PATH+id_))\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- テスト時に参照するためTestデータの情報をpickleで保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./pickle/{}/test_ids.pickle'.format(category), 'wb')\n",
    "pickle.dump(test_ids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet作成用関数\n",
    "- エポックごとにTripletの組み合わせをランダムに変更するためpickle保存ができない\n",
    "- エポックごとに変えるのは普通なのか怪しい\n",
    "- **Tripletを200個くらい予め作成しpickle保存しておけば今後回すのが楽になるのでは。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def get_np_triplets(triplet_PATHs):\n",
    "    triplets = []\n",
    "    for triplet in tqdm(triplet_PATHs):\n",
    "        anc_img = Image.open(triplet[0]).convert('RGB')\n",
    "        pos_img = Image.open(triplet[1]).convert('RGB')\n",
    "        neg_img = Image.open(triplet[2]).convert('RGB')\n",
    "\n",
    "        anc_img = np.array(anc_img.resize((128,128)))/255. #resize to (128,128,3)\n",
    "        pos_img = np.array(pos_img.resize((128,128)))/255.    \n",
    "        neg_img = np.array(neg_img.resize((128,128)))/255.    \n",
    "\n",
    "        tri = [anc_img,pos_img,neg_img]\n",
    "        triplets.append(np.array(tri))\n",
    "\n",
    "    triplets = np.array(triplets)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 各エポックでtestデータを用いて`N-top acc`を出したい\n",
    "- epochの外でtrain,testに分割するパターンなので常にtestのidは同じ\n",
    "- `train_triplet`のnegativeが毎回ランダムになるので偏らないメリットがある->**pickle保存済みのtripletを用いれば学習を効率化できる**\n",
    "- `model.fit()`は`epochs=1`で行う\n",
    "- `model_history=[]`に各エポックにおけるメトリクス(loss/accuracy等)をappendすることで後から推移を確認できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model/T_Shirt/Dual_improved/a0.1b0.05'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = './model/{}/Dual_improved/a{}b{}'.format(category,ALPHA,BETA)\n",
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/4123 [00:00<00:22, 185.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:31<00:00, 129.54it/s]\n",
      " 14%|█▎        | 5187/38378 [00:43<03:28, 159.53it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'Image' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-64d75281141c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtriplets_train_PATHs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBASE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtriplets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_np_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets_train_PATHs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtriplets_train_PATHs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-9e7e7d4b97ae>\u001b[0m in \u001b[0;36mget_np_triplets\u001b[0;34m(triplet_PATHs)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mneg_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0manc_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manc_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m \u001b[0;31m#resize to (128,128,3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mpos_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mneg_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'Image' and 'float'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 5187/38378 [01:00<03:28, 159.53it/s]"
     ]
    }
   ],
   "source": [
    "model_history = []\n",
    "for epoch in range(epochs):\n",
    "    print('epoch %s'% epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        if epoch != 0: del triplets\n",
    "        triplets_train_PATHs = get_triplets(train_ids,BASE_PATH)\n",
    "        triplets = get_np_triplets(triplets_train_PATHs)\n",
    "        del triplets_train_PATHs\n",
    "    # fit\n",
    "    hist = tripletNet.fit([triplets[:,0],triplets[:,1],triplets[:,2]], epochs=1, batch_size=50)\n",
    "    model_history.append(hist.history)\n",
    "    f = open(model_dir+'/{}/history{}.txt'.format(vec_length,epoch),'wb')\n",
    "    pickle.dump(model_history, f)\n",
    "    # 使い終わったので削除\n",
    "##    del triplets\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        shop_embNet.save(model_dir+'/{}/shop_e{}.h5'.format(vec_length,epoch))\n",
    "        con_embNet.save(model_dir+'/{}/con_e{}.h5'.format(vec_length,epoch))\n",
    "        \n",
    "# 学習のhistoryを保存\n",
    "f = open(model_dir+'/{}/history.txt'.format(vec_length),'wb')\n",
    "pickle.dump(model_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35-zukapy",
   "language": "python",
   "name": "py35-zukapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
