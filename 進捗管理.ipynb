{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11/19\n",
    "- `mat[uid,iid]`は、評価がめちゃ高い場合のみ1.0になるスパースな行列\n",
    "- 大きさとしてはlen(uid)*len(iid)分存在。\n",
    "- consumerのみ、またはshopのみの画像しか存在しないディレクトリを削除する関数を作成。念の為T_Shirt_all2を作成してバックアップ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_tripletsについて\n",
    "- mat.rowの長さ分の乱数を発生->pidとnidが一致することもあるのでは？問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 4)\t1\n",
      "[0 0 1] [0 2 4]\n",
      "10\n",
      "[2 5 3]\n",
      "[0 0 1] [0 2 4] [6 0 5]\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "mat = sp.lil_matrix((10, 10), dtype=np.int32)\n",
    "\n",
    "#matの中で正解のペアの部分(mat[uid,pid])のみ1とする。\n",
    "mat[0,0]=1\n",
    "mat[0,2]=1\n",
    "mat[1,4]=1\n",
    "print(mat)\n",
    "mat = mat.tocoo()\n",
    "\n",
    "# matはsparseなので扱うのは値が入っているところのみ\n",
    "# mat.rowでuidのarray,mat.colでpidのarrayを取得できる\n",
    "print(mat.row,mat.col)\n",
    "# mat.shapeはmat全体の長さを返す\n",
    "print(mat.shape[1])\n",
    "\n",
    "# mat.rowの長さ分の乱数を発生->pidとnidが一致することもあるのでは？\n",
    "print(np.random.randint(mat.shape[1], size=len(mat.row)))\n",
    "print(mat.row,mat.col,np.random.randint(mat.shape[1], size=len(mat.row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.fitの引数とlossについて\n",
    "- `bpr_triplet_loss`がloss=<font color=\"red\">1.0</font>-{K.sigmoid()}になっている。<br>\n",
    "- よって、y_trainはnp.ones(len(uid))にしておけば、本来のtriplet lossであるところ？のK.sigmoid()のみが効いてくる。<br>\n",
    "- ```1.0-{1.0-K.sigmoid()}=K.sigmoid()```<br>\n",
    "- lossに設定する都合上1.0から引いていると思われる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_triplet_loss(X):\n",
    "\n",
    "    positive_item_latent, negative_item_latent, user_latent = X\n",
    "\n",
    "    # BPR loss\n",
    "    loss = 1.0 - K.sigmoid(\n",
    "        K.sum(user_latent * positive_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(user_latent * negative_item_latent, axis=-1, keepdims=True))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11/18\n",
    "特に何もやっていないので明日やることをまとめる\n",
    "- 現状`get_triplets(BASE_PATH)`でreturnされるのはconsumer,positive_shop,negative_shopのPATHの組\n",
    "- PATHの組ではなく画像の組としてreturnした方が学習上都合が良いのでは？\n",
    "- <b>(済)</b> ~~参考実装は以下のようになっている。`np.random.randint(mat.shape[1], size=len(mat.row))`では`nid`をランダムに抽出している~~\n",
    "- <font color=\"red\"　>`model.fit`の第二引数が`np.ones(len(uid))`なのはどういうこと？</font>\n",
    "- triplet lossを利用したfitの場合のラベルに当たる部分を理解する。cf.http://krasserm.github.io/2018/02/07/deep-face-recognition/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(mat):\n",
    "    return mat.row, mat.col, np.random.randint(mat.shape[1], size=len(mat.row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print('Epoch %s' % epoch)\n",
    "\n",
    "    # Sample triplets from the training data\n",
    "    uid, pid, nid = get_triplets(train)\n",
    "\n",
    "    X = {\n",
    "        'user_input': uid,\n",
    "        'positive_item_input': pid,\n",
    "        'negative_item_input': nid\n",
    "    }\n",
    "\n",
    "    model.fit(X,\n",
    "              np.ones(len(uid)),　# これ何？\n",
    "              batch_size=64,\n",
    "              nb_epoch=1,\n",
    "              verbose=0,\n",
    "              shuffle=True)\n",
    "\n",
    "    print('AUC %s' % metrics.full_auc(model, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11/17\n",
    "### やったこと\n",
    "- trainとtestの分割を以下のように定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_train_ids(ids):\n",
    "    np.random.seed(seed=32)\n",
    "    train_ids = np.random.choice(ids,int(0.75*len(ids)))\n",
    "    return train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = './T_Shirt_all/'\n",
    "ids = sorted([x for x in os.listdir(BASE_PATH)])\n",
    "\n",
    "train_ids = sample_train_ids(ids)\n",
    "#idsの中でtrain_idsに含まれていないxをtest_idsとする\n",
    "test_ids = [x for x in ids if x not in train_ids] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(ids):6377<br>\n",
    "train:4782<br>\n",
    "test:2999 <br>\n",
    "という謎の結果になってしまった。\n",
    "### やること\n",
    "- 上の現象をチェックする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11/16\n",
    "### やったこと\n",
    "- TOPSとCLOTHINGの結合->T_Shirt_allへ\n",
    "- 関数の作成(get_triplet)\n",
    "### やること\n",
    "- <b>(済)</b>　~~T_Shirt_all/trainとT_Shirt_all/testに分割~~ -> 単純にidをランダムで75%取り出す処理に\n",
    "- <b>(済)</b>　~~分割の仕方はランダムで行う？~~\n",
    "    - ```train_ids=ids[np.random.choice(len(os.listdir),0.75)]``` 的な感じで75%を取り出せるかな？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zukapy35",
   "language": "python",
   "name": "zukapy35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
