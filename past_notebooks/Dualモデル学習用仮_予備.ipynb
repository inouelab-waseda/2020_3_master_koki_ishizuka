{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dualモデル学習用\n",
    "- 後でリファクタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現状GPUメモリに乗りきらずCPUで回している<br>\n",
    "VGGの出力をあらかじめpickleとして保存することで回避可能か？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pip/koki_ishizuka/.conda/envs/py35-zukapy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Layer,Lambda\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ハイパーパラメータ\n",
    "- `alpha > beta`を満たす必要がある(元論文)\n",
    "- dense_numで特徴が潰れないように\n",
    "    - dualだから100にしてた(Singleを200次元でやったので100+100で200になるから平等性)\n",
    "    - 200+200だと多すぎる？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imheight = 128\n",
    "imwidth = 128\n",
    "channels = 3\n",
    "# ALPHA = 0.2\n",
    "ALPHA=0.1\n",
    "BETA=0.05\n",
    "dense_num = 150\n",
    "vec_length=dense_num*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG16読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pip/koki_ishizuka/.conda/envs/py35-zukapy/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "#include_top=false => Dense不要\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_tensor=Input(shape=(imwidth, imheight, channels)), input_shape=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:15]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 各ルートのCNNを共通で定義\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow network for colorized features\n",
    "# create_embNetの中でやるべき？\n",
    "inputs = Input(shape=(imwidth, imheight, channels))\n",
    "conv1 = Conv2D(32, (4,4) , padding='same', activation='relu')(inputs)\n",
    "pool1 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(conv1)\n",
    "conv2 = Conv2D(32, (4,4) , padding='same', activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(conv2)\n",
    "flatten = Flatten()(pool2) \n",
    "dense_layer = Dense(dense_num, activation='relu')(flatten)\n",
    "norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer1')(dense_layer)\n",
    "shallow_model=Model(inputs=inputs,outputs=norm_layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embNet():\n",
    "    shallow_inputs = Input(shape=(imwidth, imheight, channels))\n",
    "    x = base_model.output\n",
    "    conv1 = Conv2D(32, (4,4) , padding='same', activation='relu')(x)\n",
    "    conv2 = Conv2D(32, (4,4) , padding='same', activation='relu')(conv1)\n",
    "    flatten = Flatten()(conv2) \n",
    "    dense_layer = Dense(dense_num, activation='relu')(flatten)\n",
    "    norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(dense_layer)\n",
    "    # inputに対してshallow_modelのoutputも用意\n",
    "    x1 = norm_layer\n",
    "    x2 = shallow_model(shallow_inputs)\n",
    "    out = concatenate([norm_layer,x2])\n",
    "    return Model(inputs=[base_model.input,shallow_inputs],outputs=out)\n",
    "#     return  Model(inputs=[base_model.input], outputs=norm_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define three Inputs\n",
    "# create embNetの中でInputを定義すると明示的に3つの入力が分けられない\n",
    "a_in = Input(shape = (imheight, imwidth, channels), name='anchor_input')\n",
    "p_in = Input(shape = (imheight, imwidth, channels), name='positive_input')\n",
    "n_in = Input(shape = (imheight, imwidth, channels), name='negative_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_in = Input(shape = (imheight, imwidth, channels), name='sanchor_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習後にベクトルのencoderとして利用するので外に定義する。\n",
    "con_embNet = create_embNet()\n",
    "shop_embNet = create_embNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_emb = shop_embNet([a_in,a_in])\n",
    "p_emb = con_embNet([p_in,p_in])\n",
    "n_emb = con_embNet([n_in,n_in])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet loss\n",
    "- 実行時コメントアウトはずす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def triplet_loss(self, inputs):\n",
    "        a, p, n = inputs\n",
    "        p_dist = K.sum(K.square(a-p), axis=-1)\n",
    "        n_dist = K.sum(K.square(a-n), axis=-1)\n",
    "        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'alpha': self.alpha}\n",
    "        base_config = super(TripletLossLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer that computes the triplet loss from anchor, positive and negative embedding vectors\n",
    "triplet_loss_layer = TripletLossLayer(alpha=ALPHA, name='triplet_loss_layer')([a_emb, p_emb, n_emb])\n",
    "\n",
    "# Model that can be trained with anchor, positive negative images\n",
    "tripletNet = Model([a_in, p_in, n_in], triplet_loss_layer)\n",
    "tripletNet.compile(loss=None, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Triplet Loss\n",
    "- `Loss=[D(a,p)-D(a,n)+ALPHA]+[D(a,p)-BETA]`\n",
    "- Positiveを短くする方向に制御する\n",
    "\n",
    "https://qiita.com/tancoro/items/35d0925de74f21bfff14#improved-triplet-loss\n",
    "\n",
    "<img src=\"./readme_imgs/improved.PNG\" width=50% align=left><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, beta, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "    #a-pとa-nの距離差がmarginになるように\n",
    "#     in-class variance(Positive Variance)を抑制する項を追加\n",
    "    def triplet_loss(self, inputs):\n",
    "        a, p, n = inputs\n",
    "        p_dist = K.sum(K.square(a-p), axis=-1)\n",
    "        n_dist = K.sum(K.square(a-n), axis=-1)\n",
    "        pn_dist = K.sum(K.square(p-n), axis=-1)\n",
    "        return K.sum(K.maximum((p_dist - n_dist + self.alpha), 0) + K.maximum((p_dist - self.beta), 0), axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'alpha': self.alpha}\n",
    "        base_config = super(TripletLossLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer that computes the triplet loss from anchor, positive and negative embedding vectors\n",
    "triplet_loss_layer = TripletLossLayer(alpha=ALPHA, beta=BETA, name='triplet_loss_layer')([a_emb, p_emb, n_emb])\n",
    "\n",
    "# Model that can be trained with anchor, positive negative images\n",
    "tripletNet = Model([a_in, p_in, n_in], triplet_loss_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(tripletNet, show_shapes=True, show_layer_names=False).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#並列化\n",
    "# from keras.utils import multi_gpu_model\n",
    "# tripletNet2 = multi_gpu_model(tripletNet,gpus=2)\n",
    "# compile model\n",
    "tripletNet.compile(loss=None, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_PATH = './dataset/T_Shirt_all/'\n",
    "ids = sorted([x for x in os.listdir(BASE_PATH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id_00000001'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6155"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tripletのパスの組を返す関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "# @jit\n",
    "def get_triplets(ids,BASE_PATH):\n",
    "    triplets=[]\n",
    "    # idの選択の仕方をランダムにしたらいいのか？\n",
    "    for id_ in tqdm(ids):\n",
    "        files = sorted([BASE_PATH+id_+'/'+x for x in os.listdir(BASE_PATH+id_)])\n",
    "#         print(files)\n",
    "        con = sorted([x for x in files if 'comsumer' in x])\n",
    "        shop = sorted([x for x in files if 'shop' in x ])\n",
    "        combs = list(itertools.product(tuple(con),tuple(shop)))\n",
    "        \n",
    "        for comb in combs:\n",
    "#             print(len(comb))\n",
    "            comb = list(comb)\n",
    "            neg_id = random.choice([x for x in ids if x != id_])\n",
    "#             print(neg_id)\n",
    "#             print(len([BASE_PATH+neg_id+'/'+x for x in os.listdir(BASE_PATH+neg_id) if 'shop' in x]))\n",
    "            neg_file = random.choice([BASE_PATH+neg_id+'/'+x for x in os.listdir(BASE_PATH+neg_id) if 'shop' in x])\n",
    "            comb.append(neg_file)\n",
    "            triplets.append(comb)\n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id単位でtrainとtestを分割する\n",
    "- 元々np.random.choice()でやっていたが、ブートストラップサンプリングだったのでダメ\n",
    "- train_test_splitを利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pip/koki_ishizuka/.conda/envs/py35-zukapy/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_stateを固定しておく\n",
    "train_ids,test_ids=train_test_split(ids,test_size=0.33,random_state=0)\n",
    "# idsは今後使わないので削除\n",
    "del ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_00016780', 'id_00007427', 'id_00029554', 'id_00020254', 'id_00018517']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet作成用関数\n",
    "- エポックごとにTripletの組み合わせをランダムに変更するためpickle保存ができない\n",
    "- エポックごとに変えるのは普通？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# @jit\n",
    "def get_np_triplets(triplet_PATHs):\n",
    "    triplets = []\n",
    "    # triplets = np.ndarray\n",
    "    for triplet in tqdm(triplet_PATHs):\n",
    "\n",
    "#         anc_img = Image.fromarray(np.uint8(triplet[0])).convert('RGB')\n",
    "#         pos_img = Image.fromarray(np.uint8(triplet[1])).convert('RGB')\n",
    "#         neg_img = Image.fromarray(np.uint8(triplet[2])).convert('RGB')\n",
    "\n",
    "        anc_img = Image.open(triplet[0]).convert('RGB')\n",
    "        pos_img = Image.open(triplet[1]).convert('RGB')\n",
    "        neg_img = Image.open(triplet[2]).convert('RGB')\n",
    "\n",
    "        anc_img = np.array(anc_img.resize((128,128)))/255. #resize to (128,128,3)\n",
    "        pos_img = np.array(pos_img.resize((128,128)))/255.    \n",
    "        neg_img = np.array(neg_img.resize((128,128)))/255.    \n",
    "\n",
    "        tri = [anc_img,pos_img,neg_img]\n",
    "        triplets.append(np.array(tri))\n",
    "\n",
    "    triplets = np.array(triplets)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_idsはretrival.ipynbで参照するのでpickleとして保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('test_ids.txt', 'wb')\n",
    "pickle.dump(test_ids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 仕様について\n",
    "- 各エポックでtestデータを用いてN-top accを出したい\n",
    "    - 学習過程のデータとしては有意義だが時間がかかる\n",
    "    - 最終的なN-topしか載せていない論文がほとんど\n",
    "- epochの外でtrain,testに分割するパターンなので常にtestのidは同じ\n",
    "- train_tripletのnegativeが毎回ランダムになるので偏らないメリットがある\n",
    "- model.fitはepochs=1で行う\n",
    "\n",
    "### やるべき\n",
    "- epochごとにlossをファイル出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/4123 [00:00<00:34, 117.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:24<00:00, 169.93it/s]\n",
      "100%|██████████| 38378/38378 [04:03<00:00, 157.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pip/koki_ishizuka/.conda/envs/py35-zukapy/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 254s 7ms/step - loss: 4.2106\n",
      "epoch 1\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 3.2381\n",
      "epoch 2\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 2.3635\n",
      "epoch 3\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 1.8280\n",
      "epoch 4\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 1.4437\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:30<00:00, 136.52it/s]\n",
      "100%|██████████| 38378/38378 [04:17<00:00, 148.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 244s 6ms/step - loss: 1.4954\n",
      "epoch 6\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 1.0681\n",
      "epoch 7\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.8018\n",
      "epoch 8\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.6000\n",
      "epoch 9\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.4621\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:29<00:00, 139.07it/s]\n",
      "100%|██████████| 38378/38378 [04:00<00:00, 159.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.8046\n",
      "epoch 11\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.4973\n",
      "epoch 12\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.3463\n",
      "epoch 13\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.2665\n",
      "epoch 14\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.1977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:22<00:00, 184.66it/s]\n",
      "100%|██████████| 38378/38378 [03:23<00:00, 188.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.5397\n",
      "epoch 16\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.2832\n",
      "epoch 17\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.1842\n",
      "epoch 18\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.1407\n",
      "epoch 19\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.1130\n",
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:19<00:00, 207.92it/s]\n",
      "100%|██████████| 38378/38378 [03:24<00:00, 191.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.3932\n",
      "epoch 21\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.1794\n",
      "epoch 22\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.1110\n",
      "epoch 23\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0809\n",
      "epoch 24\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 238s 6ms/step - loss: 0.0710\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:21<00:00, 187.54it/s]\n",
      "100%|██████████| 38378/38378 [03:28<00:00, 183.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.3117\n",
      "epoch 26\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.1285\n",
      "epoch 27\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.0743\n",
      "epoch 28\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0595\n",
      "epoch 29\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 238s 6ms/step - loss: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:22<00:00, 184.71it/s]\n",
      "100%|██████████| 38378/38378 [03:28<00:00, 184.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.2518\n",
      "epoch 31\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0931\n",
      "epoch 32\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0516\n",
      "epoch 33\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0429\n",
      "epoch 34\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 238s 6ms/step - loss: 0.0450\n",
      "epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:21<00:00, 194.39it/s]\n",
      "100%|██████████| 38378/38378 [03:25<00:00, 186.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 246s 6ms/step - loss: 0.2110\n",
      "epoch 36\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.0736\n",
      "epoch 37\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0418\n",
      "epoch 38\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0349\n",
      "epoch 39\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:23<00:00, 176.62it/s]\n",
      "100%|██████████| 38378/38378 [03:29<00:00, 182.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 244s 6ms/step - loss: 0.1847\n",
      "epoch 41\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0625\n",
      "epoch 42\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0316\n",
      "epoch 43\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.0262\n",
      "epoch 44\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:22<00:00, 184.47it/s]\n",
      "100%|██████████| 38378/38378 [03:12<00:00, 199.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 244s 6ms/step - loss: 0.1610\n",
      "epoch 46\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0475\n",
      "epoch 47\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0264\n",
      "epoch 48\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.0210\n",
      "epoch 49\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:22<00:00, 181.64it/s]\n",
      "100%|██████████| 38378/38378 [03:22<00:00, 189.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 245s 6ms/step - loss: 0.1430\n",
      "epoch 51\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0434\n",
      "epoch 52\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.0203\n",
      "epoch 53\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0212\n",
      "epoch 54\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:19<00:00, 208.99it/s]\n",
      "100%|██████████| 38378/38378 [03:06<00:00, 205.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 244s 6ms/step - loss: 0.1243\n",
      "epoch 56\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0357\n",
      "epoch 57\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0194\n",
      "epoch 58\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0179\n",
      "epoch 59\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:20<00:00, 201.69it/s]\n",
      "100%|██████████| 38378/38378 [03:36<00:00, 177.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 244s 6ms/step - loss: 0.1159\n",
      "epoch 61\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0321\n",
      "epoch 62\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 239s 6ms/step - loss: 0.0167\n",
      "epoch 63\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 238s 6ms/step - loss: 0.0137\n",
      "epoch 64\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 245s 6ms/step - loss: 0.0168\n",
      "epoch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:23<00:00, 175.88it/s]\n",
      "100%|██████████| 38378/38378 [03:33<00:00, 170.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0997\n",
      "epoch 66\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 244s 6ms/step - loss: 0.0267\n",
      "epoch 67\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0135\n",
      "epoch 68\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 238s 6ms/step - loss: 0.0142\n",
      "epoch 69\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 245s 6ms/step - loss: 0.0131\n",
      "epoch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:22<00:00, 181.56it/s]\n",
      "100%|██████████| 38378/38378 [03:40<00:00, 173.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0942\n",
      "epoch 71\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 245s 6ms/step - loss: 0.0242\n",
      "epoch 72\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0123\n",
      "epoch 73\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 238s 6ms/step - loss: 0.0124\n",
      "epoch 74\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 245s 6ms/step - loss: 0.0136\n",
      "epoch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:23<00:00, 177.38it/s]\n",
      "100%|██████████| 38378/38378 [03:32<00:00, 180.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0870\n",
      "epoch 76\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 246s 6ms/step - loss: 0.0220\n",
      "epoch 77\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0118\n",
      "epoch 78\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0101\n",
      "epoch 79\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.0110\n",
      "epoch 80"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:20<00:00, 204.23it/s]\n",
      "100%|██████████| 38378/38378 [03:40<00:00, 174.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.0818\n",
      "epoch 81\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0206\n",
      "epoch 82\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0104\n",
      "epoch 83\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0094\n",
      "epoch 84\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:22<00:00, 186.83it/s]\n",
      "100%|██████████| 38378/38378 [04:01<00:00, 159.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 244s 6ms/step - loss: 0.0746\n",
      "epoch 86\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0187\n",
      "epoch 87\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0091\n",
      "epoch 88\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0094\n",
      "epoch 89\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0110\n",
      "epoch 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:21<00:00, 194.94it/s]\n",
      "100%|██████████| 38378/38378 [04:00<00:00, 159.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 244s 6ms/step - loss: 0.0673\n",
      "epoch 91\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0163\n",
      "epoch 92\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0093\n",
      "epoch 93\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0079\n",
      "epoch 94\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0096\n",
      "epoch 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:22<00:00, 183.45it/s]\n",
      "100%|██████████| 38378/38378 [03:56<00:00, 162.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 244s 6ms/step - loss: 0.0633\n",
      "epoch 96\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0170\n",
      "epoch 97\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0088\n",
      "epoch 98\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0068\n",
      "epoch 99\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:19<00:00, 207.28it/s]\n",
      "100%|██████████| 38378/38378 [03:58<00:00, 160.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0630\n",
      "epoch 101\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.0146\n",
      "epoch 102\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 245s 6ms/step - loss: 0.0069\n",
      "epoch 103\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 241s 6ms/step - loss: 0.0060\n",
      "epoch 104\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 243s 6ms/step - loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:21<00:00, 189.15it/s]\n",
      "100%|██████████| 38378/38378 [03:58<00:00, 160.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0574\n",
      "epoch 106\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0122\n",
      "epoch 107\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 240s 6ms/step - loss: 0.0077\n",
      "epoch 108\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 248s 6ms/step - loss: 0.0083\n",
      "epoch 109\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 261s 7ms/step - loss: 0.0081\n",
      "epoch 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:22<00:00, 186.51it/s]\n",
      "100%|██████████| 38378/38378 [04:07<00:00, 154.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 266s 7ms/step - loss: 0.0532\n",
      "epoch 111\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 242s 6ms/step - loss: 0.0122\n",
      "epoch 112\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 246s 6ms/step - loss: 0.0056\n",
      "epoch 113\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 273s 7ms/step - loss: 0.0062\n",
      "epoch 114\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 269s 7ms/step - loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4123/4123 [00:22<00:00, 184.23it/s]\n",
      "100%|██████████| 38378/38378 [03:56<00:00, 162.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 272s 7ms/step - loss: 0.0545\n",
      "epoch 116\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 269s 7ms/step - loss: 0.0120\n",
      "epoch 117\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 271s 7ms/step - loss: 0.0066\n",
      "epoch 118\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 250s 7ms/step - loss: 0.0059\n",
      "epoch 119\n",
      "Epoch 1/1\n",
      "38378/38378 [==============================] - 257s 7ms/step - loss: 0.0069\n"
     ]
    }
   ],
   "source": [
    "model_history = []\n",
    "for epoch in range(epochs):\n",
    "    print('epoch %s'% epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        # PATHの組みを取得\n",
    "        if epoch != 0: del triplets\n",
    "        triplets_train_PATHs = get_triplets(train_ids,BASE_PATH)\n",
    "        # np配列に変換\n",
    "        triplets = get_np_triplets(triplets_train_PATHs)\n",
    "        # 使い終わったので削除\n",
    "        del triplets_train_PATHs\n",
    "    # fit\n",
    "    hist = tripletNet.fit([triplets[:,0],triplets[:,1],triplets[:,2]], epochs=1, batch_size=50) # using batch_size is better\n",
    "    model_history.append(hist.history)\n",
    "    # 使い終わったので削除\n",
    "##    del triplets\n",
    "#     if (epoch+1) % 5 == 0:\n",
    "#         5epochごとにmodelを保存\n",
    "#         shop_embNet.save('./model/T_Shirt/improved_tripletloss/a{}b{}/{}/shop_e{}.h5'.format(ALPHA,BETA,vec_length,epoch))\n",
    "#         con_embNet.save('./model/T_Shirt/improved_tripletloss/a{}b{}/{}/con_e{}.h5'.format(ALPHA,BETA,vec_length,epoch))\n",
    "#         shop_embNet.save('./model/T_Shirt/tripletloss/a{}/{}/shop_e{}.h5'.format(ALPHA,vec_length,epoch))\n",
    "#         con_embNet.save('./model/T_Shirt/tripletloss/a{}/{}/con_e{}.h5'.format(ALPHA,vec_length,epoch))\n",
    "\n",
    "# 学習のhistoryを保存\n",
    "f = open('./model/T_Shirt/improved_tripletloss/a{}b{}/{}/history.txt'.format(ALPHA,BETA,vec_length),'wb')\n",
    "pickle.dump(model_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習のhistoryを保存\n",
    "f = open('./model/T_Shirt/improved_tripletloss/a{}b{}/{}/history.txt'.format(ALPHA,BETA,vec_length),'wb')\n",
    "pickle.dump(model_history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# updates\n",
    "- ver 0.1\n",
    "    - 学習できることを確認\n",
    "    - 1epochごとにモデルを保存できるように変更\n",
    "- ver 0.2\n",
    "    - embNetを並列化\n",
    "- ver 0.3(2019/6/30)\n",
    "    - ~~Triplet lossにshop画像間の距離を考慮するため内積を加える~~\n",
    "- 2019/10/11\n",
    "    - Improved Triplet lossを導入\n",
    "- 2019/11/17\n",
    "    - Improved Triplet lossを修正\\\n",
    "- 2019/11/22\n",
    "    - vec_length=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aaa = get_triplets(train_ids[:5],BASE_PATH)\n",
    "print(aaa)\n",
    "bbb = get_np_triplets(aaa)\n",
    "\n",
    "for b in bbb:\n",
    "#     print(b)\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.tick_params(labelbottom=False, labelleft=False, labelright=False, labeltop=False)\n",
    "    plt.tick_params(color='white')\n",
    "    plt.imshow(b[0])\n",
    "    plt.title('anchor')\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.tick_params(labelbottom=False, labelleft=False, labelright=False, labeltop=False)\n",
    "    plt.tick_params(color='white')    \n",
    "\n",
    "    plt.imshow(b[1])\n",
    "    plt.title('anchor')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.tick_params(labelbottom=False, labelleft=False, labelright=False, labeltop=False)\n",
    "    plt.tick_params(color='white')\n",
    "    plt.imshow(b[2])\n",
    "    plt.title('anchor')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35-zukapy",
   "language": "python",
   "name": "py35-zukapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
