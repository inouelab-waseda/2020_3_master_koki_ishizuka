{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Input, merge\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Input,Layer,Lambda\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras import backend as K\n",
    "# import data\n",
    "# import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "誤差関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(inputs):\n",
    "    a, p, n = inputs\n",
    "    p_dist = K.sum(K.square(a-p), axis=-1)\n",
    "    n_dist = K.sum(K.square(a-n), axis=-1)\n",
    "    return 1.0 - K.sum(K.maximum(p_dist - n_dist + alpha, 0), axis=0)\n",
    "#     return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "imheight = 128\n",
    "imwidth = 128\n",
    "channels = 3\n",
    "# ALPHA = 0.2\n",
    "alpha=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "#include_top=false => Dense不要\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_tensor=Input(shape=(imwidth, imheight, channels)), input_shape=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15層目までは訓練しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:15]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワークを定義<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embNet():\n",
    "    x = base_model.output\n",
    "    conv1 = Conv2D(32, (4,4) , padding='same', activation='relu')(x)\n",
    "    conv2 = Conv2D(32, (4,4) , padding='same', activation='relu')(conv1)\n",
    "    flatten = Flatten()(conv2) \n",
    "    dense_layer = Dense(20, activation='relu')(flatten)\n",
    "    norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(dense_layer)\n",
    "    return  Model(inputs=[base_model.input], outputs=norm_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(y_true, y_pred):\n",
    "\n",
    "    return K.mean(y_pred - 0 * y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    a_in = Input(shape = (imheight, imwidth, channels), name='anchor_input')\n",
    "    p_in = Input(shape = (imheight, imwidth, channels), name='positive_input')\n",
    "    n_in = Input(shape = (imheight, imwidth, channels), name='negative_input')\n",
    "    \n",
    "    a_emb = create_embNet()(a_in)\n",
    "    p_emb = create_embNet()(p_in)\n",
    "    n_emb = create_embNet()(n_in)\n",
    "    \n",
    "#     loss = merge(\n",
    "#         [a_emb,p_emb, n_emb],\n",
    "#         mode=triplet_loss,\n",
    "#         name='loss',\n",
    "#         output_shape=(1, ))\n",
    "    \n",
    "    loss = Lambda(lambda x: triplet_loss(x), output_shape=(1,))( [a_emb,p_emb, n_emb])\n",
    "    \n",
    "    model = Model(\n",
    "        input=[a_in,p_in,n_in],\n",
    "        output=loss)\n",
    "    \n",
    "#     model.compile(loss=identity_loss, optimizer=Adam())\n",
    "    model.compile(loss=identity_loss, optimizer=Adam())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inouelab/.conda/envs/zukapy35/lib/python3.5/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"la..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元々の\n",
    "- 'crop_imgs/img/CLOTHING/T_Shirt'\n",
    "- 'crop_imgs/img/TOPS/T_Shirt' <br>\n",
    "を結合したので\n",
    "- './T_Shirt_all/'<br>\n",
    "のみを参照すれば良い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## './T_Shirt_all/train/'と'./T_Shirt_all/test/'に分けたい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_PATH = './T_Shirt_all/'\n",
    "ids = sorted([x for x in os.listdir(BASE_PATH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_00000001', 'id_00000019', 'id_00000051', 'id_00000058', 'id_00000068']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6377"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_filenums(ids):\n",
    "    sum_ = 0\n",
    "    for id_ in ids:\n",
    "        files = sorted([BASE_PATH+id_+'/'+x for x in os.listdir(BASE_PATH+id_)])\n",
    "        sum_ += len(files)\n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40115"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_ = calc_filenums(ids)\n",
    "sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirname2int(dirname):\n",
    "    dirname = dirname[3::]\n",
    "    return int(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =======Warning!! 以下実行注意======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def rmdir(ids,PATH):\n",
    "    for id_ in ids:\n",
    "        files = sorted([BASE_PATH+id_+'/'+x for x in os.listdir(BASE_PATH+id_)])\n",
    "        con = sorted([x for x in files if 'comsumer' in x])\n",
    "        shop = sorted([x for x in files if 'shop' in x ])\n",
    "        if len(con)==0 or len(shop)==0:\n",
    "            shutil.rmtree(PATH+id_)    \n",
    "    return os.listdir(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ids = rmdir(ids,PATH=BASE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "def get_triplets(ids,BASE_PATH):\n",
    "    triplets=[]\n",
    "    # idの選択の仕方をランダムにしたらいいのか？\n",
    "    for id_ in ids:\n",
    "        files = sorted([BASE_PATH+id_+'/'+x for x in os.listdir(BASE_PATH+id_)])\n",
    "#         print(files)\n",
    "        con = sorted([x for x in files if 'comsumer' in x])\n",
    "        shop = sorted([x for x in files if 'shop' in x ])\n",
    "        combs = list(itertools.product(tuple(con),tuple(shop)))\n",
    "        \n",
    "        for comb in combs:\n",
    "#             print(len(comb))\n",
    "            comb = list(comb)\n",
    "            neg_id = random.choice([x for x in ids if x != id_])\n",
    "#             print(neg_id)\n",
    "#             print(len([BASE_PATH+neg_id+'/'+x for x in os.listdir(BASE_PATH+neg_id) if 'shop' in x]))\n",
    "            neg_file = random.choice([BASE_PATH+neg_id+'/'+x for x in os.listdir(BASE_PATH+neg_id) if 'shop' in x])\n",
    "            comb.append(neg_file)\n",
    "            triplets.append(comb)\n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_train_ids(ids):\n",
    "    np.random.seed(seed=0)\n",
    "    train_ids = np.random.choice(ids,int(0.75*len(ids)))\n",
    "    return train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4616"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.75*len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = sample_train_ids(ids)\n",
    "#idsの中でtrain_idsに含まれていないxをtest_idsとする\n",
    "test_ids = [x for x in ids if x not in train_ids] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [dirname2int(x) for x in train_ids]\n",
    "b = [dirname2int(x) for x in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 8]\n"
     ]
    }
   ],
   "source": [
    "aaa = [3,5,6,7,9]\n",
    "bbb = [1,2,3,4,5,6,7,8,9]\n",
    "ccc = [x for x in bbb if x not in aaa]\n",
    "print(ccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(train_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set(test_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:4616\n",
      "test:2906\n"
     ]
    }
   ],
   "source": [
    "print(\"train:{0}\\ntest:{1}\".format(len(train_ids),len(test_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "l1_l2_and = set(a) & set(b)\n",
    "print(l1_l2_and)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合計が`len(ids)`とずれるのはおかしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7522"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids)+len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images:29918\n",
      "test_images:18774\n"
     ]
    }
   ],
   "source": [
    "print(\"train_images:{}\\ntest_images:{}\".format(calc_filenums(train_ids),calc_filenums(test_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4616"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comsumer_01.jpg']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(BASE_PATH+'id_00031391')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['./T_Shirt_all/id_00015437/comsumer_01.jpg',\n",
       "  './T_Shirt_all/id_00015437/shop_01.jpg',\n",
       "  './T_Shirt_all/id_00008148/shop_01.jpg'],\n",
       " ['./T_Shirt_all/id_00014893/comsumer_01.jpg',\n",
       "  './T_Shirt_all/id_00014893/shop_01.jpg',\n",
       "  './T_Shirt_all/id_00011992/shop_01.jpg'],\n",
       " ['./T_Shirt_all/id_00014893/comsumer_01.jpg',\n",
       "  './T_Shirt_all/id_00014893/shop_02.jpg',\n",
       "  './T_Shirt_all/id_00000760/shop_01.jpg'],\n",
       " ['./T_Shirt_all/id_00014893/comsumer_02.jpg',\n",
       "  './T_Shirt_all/id_00014893/shop_01.jpg',\n",
       "  './T_Shirt_all/id_00008383/shop_01.jpg'],\n",
       " ['./T_Shirt_all/id_00014893/comsumer_02.jpg',\n",
       "  './T_Shirt_all/id_00014893/shop_02.jpg',\n",
       "  './T_Shirt_all/id_00015025/shop_01.jpg']]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = get_triplets(train_ids,BASE_PATH) \n",
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def get_np_triplets(triplet_PATHs):\n",
    "    triplets = []\n",
    "    # triplets = np.ndarray\n",
    "    for triplet in triplet_PATHs:\n",
    "\n",
    "#         anc_img = Image.fromarray(np.uint8(triplet[0])).convert('RGB')\n",
    "#         pos_img = Image.fromarray(np.uint8(triplet[1])).convert('RGB')\n",
    "#         neg_img = Image.fromarray(np.uint8(triplet[2])).convert('RGB')\n",
    "\n",
    "        anc_img = Image.open(triplet[0]).convert('RGB')\n",
    "        pos_img = Image.open(triplet[1]).convert('RGB')\n",
    "        neg_img = Image.open(triplet[2]).convert('RGB')\n",
    "\n",
    "        anc_img = np.array(anc_img.resize((128,128)))/255. #resize to (128,128,3)\n",
    "        pos_img = np.array(pos_img.resize((128,128)))/255.    \n",
    "        neg_img = np.array(neg_img.resize((128,128)))/255.    \n",
    "\n",
    "        tri = [anc_img,pos_img,neg_img]\n",
    "        triplets.append(np.array(tri))\n",
    "\n",
    "    triplets = np.array(triplets)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1epochのfitをfor文で回す\n",
    "これによりnb_epochで指定するよりもコードに自由度が出る\n",
    "- 1epochごとにtrainのアイテム集合からtripletを作成する。\n",
    "- 毎回nidが変わるので乱数によるnidのばらつきを吸収できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'mode')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-671884cecb64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-199-f6143d13fbb5>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtriplet_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         output_shape=(1, ))\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     model = Model(\n",
      "\u001b[0;32m~/.conda/envs/zukapy35/lib/python3.5/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \"\"\"\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/zukapy35/lib/python3.5/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axis, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/zukapy35/lib/python3.5/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Merge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/zukapy35/lib/python3.5/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keyword argument not understood:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'mode')"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inouelab/.conda/envs/zukapy35/lib/python3.5/site-packages/ipykernel_launcher.py:20: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([[[[[0.79215686, 0.5372549 , 0.38039216],\n          [0.79215686, 0.5372549 , 0.38039216],\n          [0.74901961, 0.49411765, 0.3372549 ],\n          ...,\n          [0.13333333, 0.1254902 , 0.145...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-18294aecc260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m               \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m               shuffle=True)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#     print('AUC %s' % metrics.full_auc(model, test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/zukapy35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/zukapy35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/zukapy35/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([[[[[0.79215686, 0.5372549 , 0.38039216],\n          [0.79215686, 0.5372549 , 0.38039216],\n          [0.74901961, 0.49411765, 0.3372549 ],\n          ...,\n          [0.13333333, 0.1254902 , 0.145..."
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print('Epoch %s' % epoch)\n",
    "\n",
    "    # Sample triplets from the training data\n",
    "    x_train_PATHs = get_triplets(train_ids,BASE_PATH)\n",
    "    X = get_np_triplets(x_train_PATHs)\n",
    "    \n",
    "#     X = {\n",
    "#         'anchor_input': uid,\n",
    "#         'positive_input': pid,\n",
    "#         'negative_input': nid\n",
    "#     }\n",
    "\n",
    "    model.fit(X,\n",
    "              np.ones(len(X)),\n",
    "              batch_size=64,\n",
    "              nb_epoch=1,\n",
    "              verbose=1,\n",
    "              shuffle=True)\n",
    "\n",
    "#     print('AUC %s' % metrics.full_auc(model, test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print('Epoch %s' % epoch)\n",
    "\n",
    "    # Sample triplets from the training data\n",
    "    uid, pid, nid = get_triplets(train)\n",
    "    \n",
    "\n",
    "    X = {\n",
    "        'user_input': uid,\n",
    "        'positive_item_input': pid,\n",
    "        'negative_item_input': nid\n",
    "    }\n",
    "\n",
    "    model.fit(X,\n",
    "              np.ones(len(uid)),\n",
    "              batch_size=64,\n",
    "              nb_epoch=1,\n",
    "              verbose=0,\n",
    "              shuffle=True)\n",
    "\n",
    "    print('AUC %s' % metrics.full_auc(model, test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zukapy35",
   "language": "python",
   "name": "zukapy35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
